{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import TFDistilBertForSequenceClassification \n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments\n",
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/cleaned_data_10000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepairing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling data\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "# Picking first 1000 rows of data\n",
    "df = df.head(1000)\n",
    "\n",
    "# Renaming values\n",
    "df[\"Score\"] = df[\"Score\"].replace([-1, 0, 1], [\"negative\", \"neutral\", \"positive\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding text\n",
    "df[\"encoded_score\"] = df[\"Score\"].astype(\"category\").cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting lists of text and labels\n",
    "data_texts = df[\"Text\"].to_list()\n",
    "\n",
    "data_labels = df[\"encoded_score\"].to_list()\n",
    "\n",
    "type(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(data_texts, data_labels, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiliazing Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenizing texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Converting DataFrames to DataSets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing training arguments\n",
    "training_args = TFTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=7,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=1e-5,\n",
    "    logging_dir='./logs',\n",
    "    eval_steps=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing trainer model\n",
    "with training_args.strategy.scope():\n",
    "    trainer_model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels = 3 )\n",
    "\n",
    "trainer = TFTrainer(\n",
    "  model=trainer_model, \n",
    "  args=training_args, \n",
    "  train_dataset=train_dataset,\n",
    "  eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model\n",
    "trainer.train()\n",
    "\n",
    "# Evualiting model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "save_directory = \"finetuned_distilled_bert\"\n",
    "\n",
    "trainer_model.save_pretrained(save_directory)\n",
    "\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"finetuned_distilled_bert\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadind model\n",
    "\n",
    "tokenizer_fine_tuned = DistilBertTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "model_fine_tuned = TFDistilBertForSequenceClassification.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Toknizer and Model\n",
    "\n",
    "tokenizer_fine_tuned_pt = DistilBertTokenizer.from_pretrained(save_directory)\n",
    "\n",
    "model_fine_tuned_pt = DistilBertForSequenceClassification.from_pretrained(save_directory, from_tf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting\n",
    "\n",
    "# Text to Classify\n",
    "test_text = \"oreos are bad\"\n",
    "\n",
    "# Tokenizing text\n",
    "predict_input = tokenizer_fine_tuned.encode(\n",
    "    test_text,\n",
    "    truncation = True,\n",
    "    padding = True,\n",
    "    return_tensors = \"tf\"\n",
    ")\n",
    "\n",
    "# Passing tokenized text to model\n",
    "output = model_fine_tuned(predict_input)[0]\n",
    "\n",
    "# Getting classfication\n",
    "prediction_value = tf.argmax(output, axis=1).numpy()[0]\n",
    "prediction_value \n",
    "\n",
    "# Positive : 2\n",
    "# Neutral : 1\n",
    "# Negative : 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
